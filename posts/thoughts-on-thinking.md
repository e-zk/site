# Thoughts on "Thoughts on Thinking"

I came across [this post](https://dcurt.is/thinking)
on [the orange site](https://news.ycombinator.com/item?id=44008843) about
someone feeling "stuck" because they've relied on AI way too much.
It got me thinking of how defeatist, and pathetic it kind of sounded to me.
This article is not directed at the author, Dustin, personally, it's my
thoughts on his thoughts. When I say "you", I really mean _you_, dear reader.
My tone in this article/rebuttal/review or whatever may come across as rude,
mean-spirited, but I mean no harm to the author, Dustin Curtis.
It may sound like I have just called him pathetic, but I don't think he's
pathetic at all, I think the tone of his post is kind of pathetic (sorry).
I'd like to preface that My tone is meant to be "tough love", rather than
cynical, or bullish, don't take it personally `:)`.

> I have been stuck. Every time I sit down to write a blog post, code a
> feature, or start a project, I come to the same realization: in the context
> of AI, what I’m doing is a waste of time. It’s horrifying. The fun has been
> sucked out of the process of creation because nothing I make organically can
> compete with what AI already produces&emdash;or soon will. All of my original
> thoughts feel like early drafts of better, more complete thoughts that simply
> haven’t yet formed inside an LLM.

To start off how about don't do that?  
How about _not_ starting a project or blog post thinking about it in
"the context of AI".  
How about _not_ thinking that your thoughts have to be run through into an LLM
to be "complete"? 

Your thoughts _are_ incomplete, they _are all early drafts_. That's okay.
Human thought is unstructured, chaotic, and just kind of inconsistent and crap
half the time. That's what we are, that's how we think, that's reality.
Hell, I'm still not even sure if writing this post is a good idea.

And come to think of it, I don't understand how people think LLM slop isn't
inconsistent and crap either?
I don't understand how an LLM output is anymore "complete" or "better" than the
"early drafts" (minus say spelling + grammar corrections I suppose). Because as
people have shown often, LLMs spit out bullshit and LLMs have the same monotone
"cadence", the same prose. This writing style of LLMs is noticeable to many.  
Please write stuff in your own words, your own tone, your own style, LLMs are
so boring.

You can tell, with 90% accuracy, when a post or a comment online or an email
or a presentation is written by AI. (I can tell, anyway `:P`).

I think maybe the benefit of me personally staying clear of all AI/LLM-related
software, "helpers", "assistants", is that I really don't think about it at
all. I don't think about plugging an idea into there. I just write it down, and
it gets lost for a few months, or never comes to fruition. Maybe I'm wrong but
I think that's completely okay.  
We don't need to take very idea and iron it out and push it out as a product or
a project or whatever. We can just sit on things,
forget things, let them rot and never even consider them again. Again, it's just
fine... A fact of life... Whatever happens will happen. That's my opinion,
anyway.

> I used to write prolifically. I’d have ideas, write them down, massage them
> slowly and carefully into cohesive pieces of work over time, and then–when
> they were ready–share them with the world. I’d obsess for hours before
> sharing anything, working through the strengths and weaknesses of my
> thinking.

WTF? _You can still do this_, all of this, by exercising some goddamn
discipline! Don't login to ChatGPT (or whatever). For one day just don't open
it up. Don't use AI tools.
Then after that one day... Do it again the next day.
It will probably be hard at first if you rely on it so much.
But your brain will benefit and you'll get out of your creative rut.

Your thoughts are stupid. All of our thoughts are stupid. This post of mine
here is _really stupid_. LLMs kind of just sugar coat the stupid, don't they?

Following from the quote above;

> Early in my career, that process brought a lot of external validation. And
> because I think when I write, and writing is how I form opinions and work
> through holes in my arguments, my writing would lead to more and better
> thoughts over time. Thinking is compounding–the more you think, the better
> your thoughts become.

Yes! Not even the brightest minds in history would think in perfect ideas. Good
writers write, and re-write, and proof read and re-write again, and again, and
again. And each time they do that they gain some kind of something --
knowledge, insight, skill, "better writing", whatever. I say this without any
hard evidence to back it up (just like an LLM, I guess) but it's true, and you
know it's true.

> But now, when my brain spontaneously forms a tiny sliver of a potentially
> interesting concept or idea, I can just shove a few sloppy words into a
> prompt and almost instantly get a fully reasoned, researched, and completed
> thought.

Well, you need to stop doing this mate...

> Minimal organic thinking required. This has had a dramatic and profound
> effect on my brain. My thinking systems have atrophied, and I can feel
> it–I can sense my slightly diminishing intuition, cleverness, and rigor.
> And because AI can so easily flesh out ideas, I feel less inclined to share
> my thoughts–no matter how developed.

Yeah... This is pretty scary, for everyone, actually. And I've noticed it with
people in my life too. This needs to be unlearned.

> I thought I was using AI in an incredibly positive and healthy way, as a
> bicycle for my mind and a way to vastly increase my thinking capacity.
> But LLMs are insidious–using them to explore ideas feels like work, but it’s
> not real work. Developing a prompt is like scrolling Netflix, and reading the
> output is like watching a TV show. Intellectual rigor comes from the journey:
> the dead ends, the uncertainty, and the internal debate. Skip that, and you
> might still get the insight–but you’ll have lost the infrastructure for
> meaningful understanding. Learning by reading LLM output is cheap. Real
> exercise for your mind comes from building the output yourself. 

Totally agreed on this. Dennis, you kind of put my thoughts above into better
words.

> And I’m still stuck. But at least I’m here, writing this, and conveying my
> raw thoughts directly into your brain. And that means something, I think,
> even though an AI could probably have written this post far more quickly,
> eloquently, and concisely. It’s horrifying. 

The only thing that's horrifying is the fact that people think that something
being generated quickly, eloquently and concisely, means that its worth more
than human-written text. When people write, and other people read it, 
it's like lofi consciousness to consciousness communication. I'm not trying to
get metaphysical or spiritual here but a writer benefits from writing, and a
reader benefits similarly too. Writing style/prose can be an art, even on
a techbro blog post. And I've kind of already said what I feel about LLM's
"prose".  
Besides, I don't really think it really could write your post more eloquently.
It conveys your feelings, in "your language", your prose.

And that's kinda... cool? We need to keep doing this.

To conclude, are you just going to sit there and be "stuck"? Or are you going
to create? Are you going to write more posts like that one?
(Yes, the one I just called pathetic).  
Write flawed shit. Write with spelling mistakes, and grammatical errors and
logical inconsistencies. Write code, brain to editor. Scratch shit down on
pen and paper, with your hands. Make it messy, unstructured notes, arrows
pointing backwards and forwards and scribbling "what the fuck?" next to
something you don't understand so you can search it up later.

If you're serious about fighting against your self-described atrophy, you need
to be disciplined. Do not reach for the ChatGPT, disable AI code suggestions.
Use your hands, your brain.  
Have bad ideas and fail often.   
Have bad ideas and forget them.  

